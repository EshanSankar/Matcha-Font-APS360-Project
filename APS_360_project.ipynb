{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCxD3KrOQOeU"
      },
      "source": [
        "# APS360 Group Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TNmulY7lunm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "global device\n",
        "print(\"Cuda Available:\", torch.cuda.is_available())\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FONT_DATASET_PATH = \"./fonts_image_dataset\"\n",
        "# Convert the images to tensors and normalize them\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), transforms.Grayscale(num_output_channels=1)])\n",
        "fonts_dataset = torchvision.datasets.ImageFolder(root = FONT_DATASET_PATH, transform=transform)\n",
        "    \n",
        "num_classes = len(fonts_dataset.classes)\n",
        "    \n",
        "# Create a list of indices for all the images in the dataset\n",
        "dataset_size = len(fonts_dataset)\n",
        "indices = list(range(dataset_size))\n",
        "np.random.seed(0)\n",
        "np.random.shuffle(indices)\n",
        "np.savetxt(\"indices\", indices)\n",
        "# Split the indices into 60% Training 20% Validation 20% Testing\n",
        "split1 = int(0.6 * dataset_size)\n",
        "split2 = int(0.8 * dataset_size)\n",
        "train_indices, val_indices, test_indices = indices[:split1], indices[split1:split2], indices[split2:]\n",
        "# Create a sampler for the training, validation, and testing sets\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "test_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "\n",
        "#FONT_DATASET_PATH2 = \"./fonts_image_dataset_no_rotations\"\n",
        "# Dataset 2\n",
        "#fonts_dataset2 = torchvision.datasets.ImageFolder(root = FONT_DATASET_PATH2, transform=transform)\n",
        "\n",
        "\n",
        "def load_dataset(f_dataset = fonts_dataset, batch_size = 32):\n",
        "    \n",
        "    def custom_collate_fn(batch):\n",
        "    \n",
        "        # Use the default collate function to batch the data (images)\n",
        "        batch = default_collate(batch)\n",
        "        images, labels = batch\n",
        "        \n",
        "        # Apply one-hot encoding to the labels\n",
        "        labels = F.one_hot(labels, num_classes=num_classes)\n",
        "\n",
        "        return images, labels\n",
        "\n",
        "    # Create the dataloaders for the training, validation, and testing sets\n",
        "    train_loader = torch.utils.data.DataLoader(f_dataset, batch_size=batch_size,sampler=train_sampler,collate_fn=custom_collate_fn)\n",
        "    val_loader = torch.utils.data.DataLoader(f_dataset, batch_size=batch_size,sampler=val_sampler,collate_fn=custom_collate_fn)\n",
        "    test_loader = torch.utils.data.DataLoader(f_dataset, batch_size=batch_size,sampler=test_sampler,collate_fn=custom_collate_fn)\n",
        "\n",
        "    print(\"Done Loading Data\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader, f_dataset.classes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions for Training and some Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def total_error(outputs, labels):\n",
        "    \n",
        "    # Find the indices of the max values\n",
        "    _, indices = torch.max(outputs, dim=1, keepdim=True)\n",
        "\n",
        "    # Create a tensor of zeros with the same shape as x\n",
        "    zeros = torch.zeros_like(outputs)\n",
        "\n",
        "    # Set the max values to 1\n",
        "    zeros.scatter_(1, indices, 1)\n",
        "    \n",
        "    return (zeros != labels).any(dim=1).float().sum()\n",
        "\n",
        "def evaluate(net, loader):\n",
        "\n",
        "    net.eval()\n",
        "    \n",
        "    total_loss = 0.0\n",
        "    total_err = 0.0\n",
        "    total_epoch = 0\n",
        "    \n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(loader, 0):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = net(inputs)\n",
        "            \n",
        "            # Calculate the statistics\n",
        "\n",
        "            total_err += total_error(outputs, labels)\n",
        "            total_loss += criterion(outputs, labels.float()).item()\n",
        "            total_epoch += len(labels)\n",
        "\n",
        "    loss = float(total_loss) / (i + 1)\n",
        "    err = float(total_err) / total_epoch\n",
        "    return err, loss\n",
        "    \n",
        "def train_net(net, model_name, BATCH_SIZE = 128, learning_rate = 0.01, num_epochs = 30, patience = None):\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    torch.manual_seed(0)\n",
        "    torch.cuda.manual_seed(0)\n",
        "    train_loader, val_loader, test_loader, classes = load_dataset(f_dataset = fonts_dataset, batch_size = BATCH_SIZE)\n",
        "\n",
        "\n",
        "    # Create the directory to store model if it does not exist\n",
        "    if not os.path.exists(model_name):\n",
        "      os.makedirs(model_name)\n",
        "    \n",
        "    # Set the seed for reproducibility\n",
        "    torch.manual_seed(0)\n",
        "    torch.cuda.manual_seed(0)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "        \n",
        "    optimizer = optim.AdamW(net.parameters(), lr=learning_rate,weight_decay=1e-3)\n",
        "\n",
        "    if patience != None:\n",
        "        num_epochs = 60\n",
        "    \n",
        "    # Set up some numpy arrays to store the loss/error rate\n",
        "    train_err = np.zeros(num_epochs)\n",
        "    train_loss = np.zeros(num_epochs)\n",
        "    val_err = np.zeros(num_epochs)\n",
        "    val_loss = np.zeros(num_epochs)\n",
        "    \n",
        "    min_validation_loss = 10000000\n",
        "    min_validation_err = 10000000\n",
        "    stop_counter = 0\n",
        "    \n",
        "    print(\"Starting Training\")\n",
        "    \n",
        "    # Train the network\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        total_train_loss = 0.0\n",
        "        total_train_err = 0.0\n",
        "        total_epoch = 0\n",
        "        \n",
        "        \n",
        "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "                        \n",
        "            net.train()\n",
        "            \n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass, backward pass, and optimize\n",
        "            outputs = net(inputs)\n",
        "            \n",
        "            loss = criterion(outputs, labels.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            net.eval()\n",
        "            \n",
        "            # Calculate the statistics\n",
        "            total_train_err += total_error(outputs, labels)\n",
        "            total_train_loss += loss.item()\n",
        "            total_epoch += len(labels)\n",
        "            \n",
        "        train_loss[epoch] = float(total_train_loss) / (i+1)\n",
        "        \n",
        "        train_err[epoch] = float(total_train_err) / total_epoch\n",
        "        val_err[epoch], val_loss[epoch] = evaluate(net, val_loader)\n",
        "        # Print the statistics\n",
        "        print(f\"Epoch {epoch + 1}: Train err: {train_err[epoch]}, Train loss: {train_loss[epoch]} | Validation err: {val_err[epoch]}, Validation loss: {val_loss[epoch]}\")\n",
        "        # Write the err into CSV file for plotting later\n",
        "        np.savetxt(f\"{model_name}/val_err.csv\", val_err)\n",
        "        np.savetxt(f\"{model_name}/train_err.csv\", train_err)\n",
        "                \n",
        "        \n",
        "        # Write the loss into CSV file for plotting later\n",
        "        np.savetxt(f\"{model_name}/train_loss.csv\", train_loss)\n",
        "        np.savetxt(f\"{model_name}/val_loss.csv\", val_loss)\n",
        "        \n",
        "        # Save the best model\n",
        "\n",
        "        if val_err[epoch] <= min_validation_err:\n",
        "            min_validation_err = val_err[epoch]\n",
        "            torch.save(net.state_dict(), f\"{model_name}/best_model\")\n",
        "            stop_counter = 0\n",
        "        else:\n",
        "            stop_counter += 1\n",
        "        \n",
        "        if patience != None and stop_counter >= patience:\n",
        "            break\n",
        "        \n",
        "\n",
        "    print('Finished Training')\n",
        "    net.load_state_dict(torch.load(f\"{model_name}/best_model\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_curve(path):\n",
        "    train_err = np.loadtxt(\"{}/train_err.csv\".format(path))\n",
        "    val_err = np.loadtxt(\"{}/val_err.csv\".format(path))\n",
        "    train_loss = np.loadtxt(\"{}/train_loss.csv\".format(path))\n",
        "    val_loss = np.loadtxt(\"{}/val_loss.csv\".format(path))\n",
        "    plt.title(\"Train vs Validation Error\")\n",
        "    num_epochs = len(train_err)\n",
        "    plt.plot(range(1,num_epochs+1), train_err, label=\"Train\")\n",
        "    plt.plot(range(1,num_epochs+1), val_err, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Error\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    plt.title(\"Train vs Validation Loss\")\n",
        "    plt.plot(range(1,num_epochs+1), train_loss, label=\"Train\")\n",
        "    plt.plot(range(1,num_epochs+1), val_loss, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()  \n",
        "\n",
        "def visualize_output(net, num_images = 5, f_dataset = fonts_dataset):\n",
        "\n",
        "    # Load the data\n",
        "    train_loader, val_loader, test_loader, classes = load_dataset(f_dataset = f_dataset, batch_size = num_images)\n",
        "    dataiter = iter(test_loader)\n",
        "    images, labels = next(dataiter)\n",
        "    net = net.to(\"cpu\")\n",
        "    # Get ground truth labels\n",
        "    ground_truth = [classes[np.argmax(labels[j], axis=0)] for j in range(num_images)]\n",
        "\n",
        "    # Get model predictions\n",
        "    outputs = net(images)\n",
        "    outputs_np = outputs.detach().numpy()\n",
        "    best3ind = np.argsort(outputs_np,axis=1)[:,-3:][:, ::-1] \n",
        "    best3prob = np.sort(outputs_np,axis=1)[:,-3:][:, ::-1]\n",
        "    predicted = [['%s, confidence: %s'%(classes[best3ind[i][j]], round(best3prob[i][j]*100,2))+'%' for j in range(3)] for i in range(num_images)]\n",
        "\n",
        "    fig, axs = plt.subplots(1, num_images, figsize=(30, 20))\n",
        "\n",
        "    # Print Images\n",
        "    for i in range(num_images):\n",
        "        img = images[i]\n",
        "        npimg = img.numpy()\n",
        "\n",
        "        axs[i].imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')\n",
        "        axs[i].set_yticklabels([])\n",
        "        axs[i].set_xticklabels([])\n",
        "        axs[i].set_xticks([])\n",
        "        axs[i].set_yticks([])\n",
        "\n",
        "        axs[i].set_title(f\"Prediction: {predicted[i][0]} \\n {predicted[i][1]} \\n {predicted[i][2]}\\n Ground Truth: {ground_truth[i]}\",fontsize = 24)\n",
        "    plt.show()\n",
        "    net = net.to(device)\n",
        "    \n",
        "def generate_confusion_matrix(net, model_name, f_dataset = fonts_dataset):\n",
        "  \n",
        "    # Load the data\n",
        "    train_loader, val_loader, test_loader, classes = load_dataset(f_dataset = f_dataset)\n",
        "    confusion_matrix = np.zeros((len(classes), len(classes)))\n",
        "    net = net.to(\"cpu\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(test_loader, 0):\n",
        "            if i == 100:\n",
        "                break\n",
        "                \n",
        "            # Forward pass\n",
        "            outputs = net(inputs)\n",
        "            \n",
        "            # Find the indices of the max values\n",
        "            _, indices = torch.max(outputs, dim=1, keepdim=True)\n",
        "            \n",
        "            for j in range(len(labels)):\n",
        "                confusion_matrix[np.argmax(labels[j], axis=0), indices[j]] += 1\n",
        "        \n",
        "    plt.figure(figsize=(12,10))\n",
        "    plt.imshow(confusion_matrix, interpolation='nearest')\n",
        "    plt.title('Confusion matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "    net = net.to(device)\n",
        "                \n",
        "    np.savetxt(f\"{model_name}/confusion_matrix.csv\", confusion_matrix)\n",
        "    return confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining and Training Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY_SOfBvQFya"
      },
      "outputs": [],
      "source": [
        "class BaselineModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaselineModel, self).__init__() \n",
        "        self.conv1 = nn.Conv2d(1, 5, 3) \n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(5, 10, 3)\n",
        "        self.conv3 = nn.Conv2d(10, 20, 3)\n",
        "        self.fc = nn.Linear(26*26*20, 42)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 26*26*20)\n",
        "\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PrimaryModel6c(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PrimaryModel6c, self).__init__() \n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, 2) \n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, 2)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, 2)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 32, 1)\n",
        "        self.bn4 = nn.BatchNorm2d(32)\n",
        "        self.fc1 = nn.Linear(32*27*27, 32*32)\n",
        "        self.bn5 = nn.BatchNorm1d(32*32)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(32*32, 42)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(F.relu(self.conv1(x)))\n",
        "        x = self.bn2(F.relu(self.conv2(x)))\n",
        "        x = self.bn3(F.relu(self.conv3(x)))\n",
        "        x = self.bn4(F.relu(self.conv4(x)))\n",
        "        \n",
        "        x = x.view(-1, 32*27*27)\n",
        "        \n",
        "        x = self.bn5(self.dropout(F.relu(self.fc1(x))))\n",
        "        x = F.softmax(self.fc2(x), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_model_final = BaselineModel()\n",
        "baseline_model_final = baseline_model_final.to(device)\n",
        "train_net(baseline_model_final, \"baseline_model_final\", BATCH_SIZE = 32, learning_rate = 0.005, num_epochs = 15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "primary_model_final = PrimaryModel6c()\n",
        "primary_model_final = primary_model_final.to(device)\n",
        "train_net(primary_model_final, \"primary_model_final\", BATCH_SIZE = 64, learning_rate = 0.0001, patience = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing and Visualizing Baseline Model and Primary Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader, val_loader, test_loader, classes = load_dataset(f_dataset=fonts_dataset, batch_size = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_model_final.load_state_dict(torch.load(\"baseline_model_final/best_model\"))\n",
        "baseline_model_final = baseline_model_final.to(device)\n",
        "\n",
        "test_err, test_loss = evaluate2(baseline_model_final, test_loader)\n",
        "print(f\"Test error: {test_err}, Test loss: {test_loss}\")\n",
        "plot_training_curve(\"baseline_model_final\")\n",
        "visualize_output(baseline_model_final, num_images = 5, f_dataset=fonts_dataset)\n",
        "generate_confusion_matrix(baseline_model_final, \"baseline_model_final\", f_dataset=fonts_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "primary_model_final.load_state_dict(torch.load(\"primary_model_final/best_model\"))\n",
        "primary_model_final = primary_model_final.to(device)\n",
        "\n",
        "test_err, test_loss = evaluate2(primary_model_final, test_loader)\n",
        "print(f\"Test error: {test_err}, Test loss: {test_loss}\")\n",
        "plot_training_curve(\"primary_model_final\")\n",
        "visualize_output(primary_model_final, num_images = 5, f_dataset=fonts_dataset)\n",
        "generate_confusion_matrix(primary_model_final, \"primary_model_final\", f_dataset=fonts_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing Primary Model's Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "handwritten_dataset = torchvision.datasets.ImageFolder(root = \"handwritten\", transform=transform)\n",
        "loader = torch.utils.data.DataLoader(handwritten_dataset, batch_size=len(handwritten_dataset), shuffle=True)\n",
        "handwritten_classes = handwritten_dataset.classes\n",
        "\n",
        "dataiter = iter(loader)\n",
        "images, labels = next(dataiter)\n",
        "primary_model_final = primary_model_final.to(\"cpu\")\n",
        "\n",
        "images_per_class = len(handwritten_dataset) // len(handwritten_classes)\n",
        "inputs, labels = next(iter(loader))\n",
        "outputs = primary_model_final(images)\n",
        "outputs_np = outputs.detach().numpy()\n",
        "best3ind = np.argsort(outputs_np,axis=1)[:,-3:][:, ::-1] \n",
        "best3prob = np.sort(outputs_np,axis=1)[:,-3:][:, ::-1]\n",
        "num_images = 3\n",
        "predicted = [['%s, confidence: %s'%(classes[best3ind[i][j]], round(best3prob[i][j]*100,2))+'%' for j in range(3)] for i in range(num_images)]\n",
        "\n",
        "primary_model_final = primary_model_final.to(device)\n",
        "fig, axs = plt.subplots(1, num_images, figsize=(30, 20))\n",
        "for i in range(num_images):\n",
        "        img = images[i]\n",
        "        npimg = img.numpy()\n",
        "\n",
        "        axs[i].imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')\n",
        "        axs[i].set_yticklabels([])\n",
        "        axs[i].set_xticklabels([])\n",
        "        axs[i].set_xticks([])\n",
        "        axs[i].set_yticks([])\n",
        "\n",
        "        axs[i].set_title(f\"Prediction: {predicted[i][0]} \\n {predicted[i][1]} \\n {predicted[i][2]}\",fontsize = 24)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_tsne(net, dataset, points_per_font, handwritten_dataset_path = None):\n",
        "    import sklearn\n",
        "    from sklearn.manifold import TSNE\n",
        "    import pandas as pd\n",
        "    import seaborn as sns\n",
        "    \n",
        "    train_loader, val_loader, test_loader, classes = load_dataset(dataset, batch_size = 32)\n",
        "    net = net.to(\"cpu\")\n",
        "    \n",
        "    counts = {c:0 for c in classes}\n",
        "    selected_labels = []\n",
        "    selected_embeddings = []\n",
        "    \n",
        "    if handwritten_dataset_path != None:\n",
        "        handwritten_dataset = torchvision.datasets.ImageFolder(root = handwritten_dataset_path, transform=transform)\n",
        "        loader = torch.utils.data.DataLoader(handwritten_dataset, batch_size=len(handwritten_dataset), shuffle=False)\n",
        "        handwritten_classes = handwritten_dataset.classes\n",
        "        marker_types = ['s', '*', '^', 'D']\n",
        "        markers_dict = {c:marker_types[i] for i,c in enumerate(handwritten_classes)}\n",
        "        images_per_class = len(handwritten_dataset) // len(handwritten_classes)\n",
        "    \n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(test_loader, 0):\n",
        "            \n",
        "            labels = torch.argmax(labels, dim=1)\n",
        "            \n",
        "            outputs = net(inputs)\n",
        "                        \n",
        "            for j in range(inputs.shape[0]):\n",
        "                \n",
        "                word_label = classes[labels[j].item()]\n",
        "                \n",
        "                if counts[word_label] < points_per_font:\n",
        "                    \n",
        "                    selected_labels.append(word_label)\n",
        "                    selected_embeddings.append(outputs[j].numpy())\n",
        "                    counts[word_label] += 1\n",
        "            \n",
        "            if all([counts[c] == points_per_font for c in classes]):\n",
        "                break\n",
        "                    \n",
        "            print(i, end=\",\")\n",
        "        \n",
        "        num_generated_points = len(selected_labels)\n",
        "        \n",
        "        if handwritten_dataset_path != None:\n",
        "            inputs, labels = next(iter(loader))\n",
        "            outputs = net(inputs)\n",
        "            for j in range(inputs.shape[0]):\n",
        "                selected_labels.append(handwritten_classes[labels[j].item()])\n",
        "                selected_embeddings.append(outputs[j].numpy())\n",
        "\n",
        "        \n",
        "    selected_embeddings = np.array(selected_embeddings)\n",
        "    selected_labels = np.array(selected_labels)\n",
        "    \n",
        "    tsne = TSNE(2)\n",
        "    tsne_result = tsne.fit_transform(selected_embeddings)\n",
        "    \n",
        "    tsne_result_df = pd.DataFrame({'tsne_1': tsne_result[:num_generated_points,0], 'tsne_2': tsne_result[:num_generated_points,1], 'label': selected_labels[:num_generated_points]})\n",
        "    fig, ax = plt.subplots(1)\n",
        "    sns.scatterplot(x='tsne_1', y='tsne_2', hue='label',data=tsne_result_df, ax=ax, s=5)\n",
        "    colors = ['r', 'g', 'b', 'y']\n",
        "    for i in range(num_generated_points, len(selected_labels), images_per_class):\n",
        "        # scatter\n",
        "        ax.scatter(tsne_result[i:i+images_per_class,0], tsne_result[i:i+images_per_class,1], c=colors[(i-num_generated_points)//images_per_class], edgecolors = 'black', s=20, marker=markers_dict[selected_labels[i]], label =selected_labels[i])\n",
        "    \n",
        "    lim = (tsne_result.min()-5, tsne_result.max()+5)\n",
        "    ax.set_xlim(lim)\n",
        "    ax.set_ylim(lim)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.set_xlabel('t-SNE 1')\n",
        "    ax.set_ylabel('t-SNE 2')\n",
        "    legend = ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0, ncol=3, markerscale=3)    \n",
        "    fig.savefig('tsne.png')\n",
        "    net = net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generate_tsne(net = primary_model_final, dataset = fonts_dataset, points_per_font = 20, handwritten_dataset_path=\"handwritten\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
